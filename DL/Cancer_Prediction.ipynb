{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cancer Prediction.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMmsT5qVPZpdqNOEb08d3/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HHansi/Applied-AI-Course/blob/main/DL/Cancer_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8etGIdHNvoqL"
      },
      "source": [
        "# Breast Cancer Diagnosis with NN\r\n",
        "\r\n",
        "I am using [Breast Cancer Wisconsin (Diagnostic) Data Set\r\n",
        "](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data) for this tutorial. \r\n",
        "\r\n",
        "Features available with this data set are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.<br>\r\n",
        "The diagnosed labels are 'M' and 'B' which correspond to malignant and benign.  \r\n",
        "\r\n",
        "Let's train a simple neural network to predict the tumor type given the features computed from digitized images. \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC4djlmOxd-P"
      },
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yMPDRlZvs6N",
        "outputId": "0bb9f473-60c7-4088-c1ab-be867dccf668"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9AVz4Jjxkar"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGpi4ftCR3qp"
      },
      "source": [
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "\r\n",
        "from sklearn import metrics"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DtsGMwFvZKu"
      },
      "source": [
        "## Load and analyse the data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "JUqzeZTXR5_m",
        "outputId": "ce705bc9-8fda-4c3a-c9f9-f2f8511ca20e"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Applied-AI/DL/data/cancer_data.csv')\r\n",
        "\r\n",
        "# summarise the details\r\n",
        "print(f'Number of entries: {len(df)}')\r\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of entries: 569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "0    842302         M  ...          0.4601                  0.11890\n",
              "1    842517         M  ...          0.2750                  0.08902\n",
              "2  84300903         M  ...          0.3613                  0.08758\n",
              "3  84348301         M  ...          0.6638                  0.17300\n",
              "4  84358402         M  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij6zxxyqTINw",
        "outputId": "0294ca78-c555-4a31-afb4-0c7ff7c93c89"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 32 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30), int64(1), object(1)\n",
            "memory usage: 142.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "m3g17MJuTPmZ",
        "outputId": "d6c83fe3-c7d7-44ea-de30-c08e4272797d"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.037183e+07</td>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.250206e+08</td>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.670000e+03</td>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.692180e+05</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.060240e+05</td>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.813129e+06</td>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.113205e+08</td>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "count  5.690000e+02   569.000000  ...      569.000000               569.000000\n",
              "mean   3.037183e+07    14.127292  ...        0.290076                 0.083946\n",
              "std    1.250206e+08     3.524049  ...        0.061867                 0.018061\n",
              "min    8.670000e+03     6.981000  ...        0.156500                 0.055040\n",
              "25%    8.692180e+05    11.700000  ...        0.250400                 0.071460\n",
              "50%    9.060240e+05    13.370000  ...        0.282200                 0.080040\n",
              "75%    8.813129e+06    15.780000  ...        0.317900                 0.092080\n",
              "max    9.113205e+08    28.110000  ...        0.663800                 0.207500\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "8Tl3eTGkIoUF",
        "outputId": "c887c63e-606a-4676-baa6-04cc2f986745"
      },
      "source": [
        "# Summarise class details\r\n",
        "sns.countplot(x=df['diagnosis'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7870e9fd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obRIxYt5UeR8"
      },
      "source": [
        "## Extracting labels and features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "aMdHo-B4Uexd",
        "outputId": "430711a2-2e3d-4fdb-99d9-6eb154e3047a"
      },
      "source": [
        "# extract labels\r\n",
        "y = df['diagnosis']\r\n",
        "y = pd.Series(y)\r\n",
        "print(y.value_counts())\r\n",
        "\r\n",
        "# remove unnecessary columns\r\n",
        "X = df.drop(['id', 'diagnosis'], axis=1)\r\n",
        "print(X.info())\r\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "B    357\n",
            "M    212\n",
            "Name: diagnosis, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 30 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   radius_mean              569 non-null    float64\n",
            " 1   texture_mean             569 non-null    float64\n",
            " 2   perimeter_mean           569 non-null    float64\n",
            " 3   area_mean                569 non-null    float64\n",
            " 4   smoothness_mean          569 non-null    float64\n",
            " 5   compactness_mean         569 non-null    float64\n",
            " 6   concavity_mean           569 non-null    float64\n",
            " 7   concave points_mean      569 non-null    float64\n",
            " 8   symmetry_mean            569 non-null    float64\n",
            " 9   fractal_dimension_mean   569 non-null    float64\n",
            " 10  radius_se                569 non-null    float64\n",
            " 11  texture_se               569 non-null    float64\n",
            " 12  perimeter_se             569 non-null    float64\n",
            " 13  area_se                  569 non-null    float64\n",
            " 14  smoothness_se            569 non-null    float64\n",
            " 15  compactness_se           569 non-null    float64\n",
            " 16  concavity_se             569 non-null    float64\n",
            " 17  concave points_se        569 non-null    float64\n",
            " 18  symmetry_se              569 non-null    float64\n",
            " 19  fractal_dimension_se     569 non-null    float64\n",
            " 20  radius_worst             569 non-null    float64\n",
            " 21  texture_worst            569 non-null    float64\n",
            " 22  perimeter_worst          569 non-null    float64\n",
            " 23  area_worst               569 non-null    float64\n",
            " 24  smoothness_worst         569 non-null    float64\n",
            " 25  compactness_worst        569 non-null    float64\n",
            " 26  concavity_worst          569 non-null    float64\n",
            " 27  concave points_worst     569 non-null    float64\n",
            " 28  symmetry_worst           569 non-null    float64\n",
            " 29  fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30)\n",
            "memory usage: 133.5 KB\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0        17.99         10.38  ...          0.4601                  0.11890\n",
              "1        20.57         17.77  ...          0.2750                  0.08902\n",
              "2        19.69         21.25  ...          0.3613                  0.08758\n",
              "3        11.42         20.38  ...          0.6638                  0.17300\n",
              "4        20.29         14.34  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOYE7tUczX9J"
      },
      "source": [
        "Since we have characters ('M' and 'B') as labels, they need to be converted into numeric values. <br>\r\n",
        "This can be easily done using a LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Berasw03WL8m",
        "outputId": "b632b8f5-4351-42c8-9805-d486e65668d8"
      },
      "source": [
        "# create LabelEncoder for labels \r\n",
        "le = LabelEncoder()\r\n",
        "le.fit(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgU4jwHFzyJr",
        "outputId": "d1ec2654-55a2-40f8-b032-417d67d52fa2"
      },
      "source": [
        "# Convert labels into numeric values\r\n",
        "y = le.transform(y)\r\n",
        "\r\n",
        "y = pd.Series(y)\r\n",
        "print(y.value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    357\n",
            "1    212\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMqu-oFyzOn9"
      },
      "source": [
        "## M1\r\n",
        "\r\n",
        "As the initial model, let's think about a simple model using 8 features and 2 hidden layers.\r\n",
        "\r\n",
        "![](https://github.com/HHansi/Applied-AI-Course/blob/main/Images/Simple_neural_network.png?raw=true)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftkl8MvhTNdM"
      },
      "source": [
        "Let's select first 8 features for this model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "wgCkgrakzQss",
        "outputId": "21053a74-e0ba-442d-c706-526542811e05"
      },
      "source": [
        "X1 = X.iloc[:, 0:8]\r\n",
        "X1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  concavity_mean  concave points_mean\n",
              "0        17.99         10.38  ...          0.3001              0.14710\n",
              "1        20.57         17.77  ...          0.0869              0.07017\n",
              "2        19.69         21.25  ...          0.1974              0.12790\n",
              "3        11.42         20.38  ...          0.2414              0.10520\n",
              "4        20.29         14.34  ...          0.1980              0.10430\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrdSUHyDTSKY"
      },
      "source": [
        "### Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2lWjlFSXNmE",
        "outputId": "e2cc3eab-031b-40e7-dc1a-41a674db4a4d"
      },
      "source": [
        "# split data to train and validation sets\r\n",
        "X_train1, X_val1, y_train1, y_val1 = train_test_split(X1, y, test_size=0.3, random_state=100)\r\n",
        "print(f'training data set size: {len(X_train1)}')\r\n",
        "print(f'validation data set size: {len(X_val1)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data set size: 398\n",
            "validation data set size: 171\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uS4W0TvTXRY"
      },
      "source": [
        "### Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zv3RcerGRYVX"
      },
      "source": [
        "A [Sequential](https://keras.io/guides/sequential_model/) model is appropriate for a plain stack of layers.<br>\r\n",
        "The layers of network can be defined using [Dense](https://keras.io/api/layers/core_layers/dense/) layers (regular densely-connected NN layers)\r\n",
        "\r\n",
        "More details about model training using Keras can be found in the documentation: [Model training APIs](https://keras.io/api/models/model_training_apis/#compile-method)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IBydCcB0s3W",
        "outputId": "4ebc86db-c9bd-4baf-867c-a0a2c09ff479"
      },
      "source": [
        "# define the keras model\r\n",
        "model1 = Sequential()\r\n",
        "model1.add(Dense(12, input_dim=8, activation='relu'))\r\n",
        "model1.add(Dense(8, activation='relu'))\r\n",
        "model1.add(Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQDmKvcY03gL"
      },
      "source": [
        "# compile the keras model\r\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgtZv9ia0_P4",
        "outputId": "6c2d54da-ea6f-443e-9982-ca3b9a40b252"
      },
      "source": [
        "# train model\r\n",
        "model1.fit(X_train1, y_train1, batch_size=50, epochs=60, validation_data=(X_val1, y_val1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 45.9408 - accuracy: 0.4006 - val_loss: 33.4781 - val_accuracy: 0.4035\n",
            "Epoch 2/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 31.5379 - accuracy: 0.3516 - val_loss: 15.7650 - val_accuracy: 0.4035\n",
            "Epoch 3/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12.3841 - accuracy: 0.3749 - val_loss: 0.6011 - val_accuracy: 0.8363\n",
            "Epoch 4/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.0002 - accuracy: 0.7448 - val_loss: 4.5036 - val_accuracy: 0.6082\n",
            "Epoch 5/60\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 2.8836 - accuracy: 0.6748 - val_loss: 0.7578 - val_accuracy: 0.7544\n",
            "Epoch 6/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.1394 - accuracy: 0.7305 - val_loss: 1.0256 - val_accuracy: 0.7544\n",
            "Epoch 7/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8061 - accuracy: 0.7886 - val_loss: 0.8765 - val_accuracy: 0.8070\n",
            "Epoch 8/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8136 - accuracy: 0.8531 - val_loss: 0.7198 - val_accuracy: 0.8304\n",
            "Epoch 9/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6213 - accuracy: 0.8455 - val_loss: 0.6365 - val_accuracy: 0.8070\n",
            "Epoch 10/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6807 - accuracy: 0.7920 - val_loss: 0.6446 - val_accuracy: 0.8363\n",
            "Epoch 11/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5054 - accuracy: 0.8598 - val_loss: 0.6751 - val_accuracy: 0.8304\n",
            "Epoch 12/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5033 - accuracy: 0.8413 - val_loss: 0.6194 - val_accuracy: 0.8304\n",
            "Epoch 13/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5226 - accuracy: 0.8241 - val_loss: 0.6333 - val_accuracy: 0.8363\n",
            "Epoch 14/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4842 - accuracy: 0.8486 - val_loss: 0.6412 - val_accuracy: 0.8363\n",
            "Epoch 15/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5394 - accuracy: 0.8504 - val_loss: 0.6207 - val_accuracy: 0.8363\n",
            "Epoch 16/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4981 - accuracy: 0.8379 - val_loss: 0.6081 - val_accuracy: 0.8363\n",
            "Epoch 17/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5230 - accuracy: 0.8351 - val_loss: 0.6474 - val_accuracy: 0.8363\n",
            "Epoch 18/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4740 - accuracy: 0.8425 - val_loss: 0.6007 - val_accuracy: 0.8304\n",
            "Epoch 19/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5488 - accuracy: 0.8174 - val_loss: 0.6085 - val_accuracy: 0.8421\n",
            "Epoch 20/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5019 - accuracy: 0.8518 - val_loss: 0.6170 - val_accuracy: 0.8421\n",
            "Epoch 21/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5518 - accuracy: 0.8345 - val_loss: 0.5926 - val_accuracy: 0.8363\n",
            "Epoch 22/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5326 - accuracy: 0.8402 - val_loss: 0.5940 - val_accuracy: 0.8363\n",
            "Epoch 23/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5135 - accuracy: 0.8531 - val_loss: 0.5958 - val_accuracy: 0.8363\n",
            "Epoch 24/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5792 - accuracy: 0.8042 - val_loss: 0.5785 - val_accuracy: 0.8363\n",
            "Epoch 25/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5321 - accuracy: 0.8311 - val_loss: 0.6215 - val_accuracy: 0.8363\n",
            "Epoch 26/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5053 - accuracy: 0.8453 - val_loss: 0.5737 - val_accuracy: 0.8363\n",
            "Epoch 27/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4921 - accuracy: 0.8292 - val_loss: 0.5960 - val_accuracy: 0.8363\n",
            "Epoch 28/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4986 - accuracy: 0.8393 - val_loss: 0.5770 - val_accuracy: 0.8421\n",
            "Epoch 29/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4691 - accuracy: 0.8431 - val_loss: 0.5595 - val_accuracy: 0.8421\n",
            "Epoch 30/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.8281 - val_loss: 0.5795 - val_accuracy: 0.8363\n",
            "Epoch 31/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5777 - accuracy: 0.8112 - val_loss: 0.5862 - val_accuracy: 0.8421\n",
            "Epoch 32/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4293 - accuracy: 0.8569 - val_loss: 0.5491 - val_accuracy: 0.8363\n",
            "Epoch 33/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5309 - accuracy: 0.7999 - val_loss: 0.5696 - val_accuracy: 0.8363\n",
            "Epoch 34/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4808 - accuracy: 0.8581 - val_loss: 0.5390 - val_accuracy: 0.8421\n",
            "Epoch 35/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5828 - accuracy: 0.8044 - val_loss: 0.5677 - val_accuracy: 0.8421\n",
            "Epoch 36/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4985 - accuracy: 0.8448 - val_loss: 0.5299 - val_accuracy: 0.8363\n",
            "Epoch 37/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5742 - accuracy: 0.8016 - val_loss: 0.5623 - val_accuracy: 0.8363\n",
            "Epoch 38/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4515 - accuracy: 0.8360 - val_loss: 0.5247 - val_accuracy: 0.8363\n",
            "Epoch 39/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4578 - accuracy: 0.8404 - val_loss: 0.5207 - val_accuracy: 0.8363\n",
            "Epoch 40/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4358 - accuracy: 0.8386 - val_loss: 0.5512 - val_accuracy: 0.8363\n",
            "Epoch 41/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.8589 - val_loss: 0.5110 - val_accuracy: 0.8421\n",
            "Epoch 42/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4406 - accuracy: 0.8329 - val_loss: 0.5296 - val_accuracy: 0.8363\n",
            "Epoch 43/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5267 - accuracy: 0.8128 - val_loss: 0.5160 - val_accuracy: 0.8421\n",
            "Epoch 44/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4832 - accuracy: 0.8350 - val_loss: 0.5015 - val_accuracy: 0.8421\n",
            "Epoch 45/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4099 - accuracy: 0.8612 - val_loss: 0.5228 - val_accuracy: 0.8363\n",
            "Epoch 46/60\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4009 - accuracy: 0.8696 - val_loss: 0.4946 - val_accuracy: 0.8421\n",
            "Epoch 47/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4754 - accuracy: 0.8461 - val_loss: 0.4916 - val_accuracy: 0.8480\n",
            "Epoch 48/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.8357 - val_loss: 0.4838 - val_accuracy: 0.8480\n",
            "Epoch 49/60\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5707 - accuracy: 0.8064 - val_loss: 0.4770 - val_accuracy: 0.8421\n",
            "Epoch 50/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3821 - accuracy: 0.8296 - val_loss: 0.5268 - val_accuracy: 0.8363\n",
            "Epoch 51/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5396 - accuracy: 0.8313 - val_loss: 0.4694 - val_accuracy: 0.8363\n",
            "Epoch 52/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4377 - accuracy: 0.8234 - val_loss: 0.4786 - val_accuracy: 0.8421\n",
            "Epoch 53/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4507 - accuracy: 0.8039 - val_loss: 0.4830 - val_accuracy: 0.8363\n",
            "Epoch 54/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5187 - accuracy: 0.8378 - val_loss: 0.4581 - val_accuracy: 0.8421\n",
            "Epoch 55/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4588 - accuracy: 0.8316 - val_loss: 0.5210 - val_accuracy: 0.8304\n",
            "Epoch 56/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4365 - accuracy: 0.8671 - val_loss: 0.4518 - val_accuracy: 0.8480\n",
            "Epoch 57/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4362 - accuracy: 0.8499 - val_loss: 0.4641 - val_accuracy: 0.8421\n",
            "Epoch 58/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3904 - accuracy: 0.8628 - val_loss: 0.4530 - val_accuracy: 0.8187\n",
            "Epoch 59/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3722 - accuracy: 0.8407 - val_loss: 0.4764 - val_accuracy: 0.8304\n",
            "Epoch 60/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3830 - accuracy: 0.8573 - val_loss: 0.4405 - val_accuracy: 0.8538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f811d9bf240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCJxLR9HTpQI"
      },
      "source": [
        "### Validate Model\r\n",
        "\r\n",
        "Validation accuracy is measure by previous step too. But, let's see how to do it separately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNT8NgNwTFqh",
        "outputId": "0398099a-e23f-40ec-f162-5638ed5dec21"
      },
      "source": [
        "# get model predictions\r\n",
        "y_pred1 = model1.predict(X_val1)\r\n",
        "print(y_pred1[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.99231267]\n",
            " [0.6719942 ]\n",
            " [0.999998  ]\n",
            " [0.01731357]\n",
            " [0.01614392]\n",
            " [0.02052468]\n",
            " [0.9991933 ]\n",
            " [0.99999356]\n",
            " [0.11461711]\n",
            " [0.01016641]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMrjL18pUhIV",
        "outputId": "d5d902d4-82ca-41da-fac9-3687d3c612dc"
      },
      "source": [
        "# convert to categorical predictions\r\n",
        "y_pred_categorical1 = [1 if pred > 0.5 else 0 for pred in y_pred1]\r\n",
        "print(y_pred_categorical1[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 0, 0, 0, 1, 1, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRLVDsFaUt50",
        "outputId": "c8d9c657-b811-49dd-fbc3-49610829be22"
      },
      "source": [
        "# measure accuracy\r\n",
        "accuracy = metrics.accuracy_score(y_val1, y_pred_categorical1)\r\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8538011695906432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCfjgcgdU-fH"
      },
      "source": [
        "### Test Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw11cj3wVwoG",
        "outputId": "9688d939-0597-42df-cdcf-61cc8f4d93e2"
      },
      "source": [
        "df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Applied-AI/DL/data/cancer_data_test.csv')\r\n",
        "\r\n",
        "# summarise the details\r\n",
        "print(f'Number of entries: {len(df_test)}')\r\n",
        "\r\n",
        "X_test = df_test.drop(['id'], axis=1)\r\n",
        "print(X_test.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of entries: 6\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6 entries, 0 to 5\n",
            "Data columns (total 30 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   radius_mean              6 non-null      float64\n",
            " 1   texture_mean             6 non-null      float64\n",
            " 2   perimeter_mean           6 non-null      float64\n",
            " 3   area_mean                6 non-null      float64\n",
            " 4   smoothness_mean          6 non-null      float64\n",
            " 5   compactness_mean         6 non-null      float64\n",
            " 6   concavity_mean           6 non-null      float64\n",
            " 7   concave points_mean      6 non-null      float64\n",
            " 8   symmetry_mean            6 non-null      float64\n",
            " 9   fractal_dimension_mean   6 non-null      float64\n",
            " 10  radius_se                6 non-null      float64\n",
            " 11  texture_se               6 non-null      float64\n",
            " 12  perimeter_se             6 non-null      float64\n",
            " 13  area_se                  6 non-null      float64\n",
            " 14  smoothness_se            6 non-null      float64\n",
            " 15  compactness_se           6 non-null      float64\n",
            " 16  concavity_se             6 non-null      float64\n",
            " 17  concave points_se        6 non-null      float64\n",
            " 18  symmetry_se              6 non-null      float64\n",
            " 19  fractal_dimension_se     6 non-null      float64\n",
            " 20  radius_worst             6 non-null      float64\n",
            " 21  texture_worst            6 non-null      float64\n",
            " 22  perimeter_worst          6 non-null      float64\n",
            " 23  area_worst               6 non-null      float64\n",
            " 24  smoothness_worst         6 non-null      float64\n",
            " 25  compactness_worst        6 non-null      float64\n",
            " 26  concavity_worst          6 non-null      float64\n",
            " 27  concave points_worst     6 non-null      float64\n",
            " 28  symmetry_worst           6 non-null      float64\n",
            " 29  fractal_dimension_worst  6 non-null      float64\n",
            "dtypes: float64(30)\n",
            "memory usage: 1.5 KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "cai6IPo2WEBH",
        "outputId": "0e6aecbc-4349-47ce-dae8-1bda2af68fe1"
      },
      "source": [
        "X_test1 = X_test.iloc[:, 0:8]\r\n",
        "X_test1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13.000</td>\n",
              "      <td>21.82</td>\n",
              "      <td>87.50</td>\n",
              "      <td>519.8</td>\n",
              "      <td>0.12730</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.18590</td>\n",
              "      <td>0.093530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.196</td>\n",
              "      <td>16.84</td>\n",
              "      <td>51.71</td>\n",
              "      <td>201.9</td>\n",
              "      <td>0.08600</td>\n",
              "      <td>0.05943</td>\n",
              "      <td>0.01588</td>\n",
              "      <td>0.005917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.170</td>\n",
              "      <td>18.66</td>\n",
              "      <td>85.98</td>\n",
              "      <td>534.6</td>\n",
              "      <td>0.11580</td>\n",
              "      <td>0.12310</td>\n",
              "      <td>0.12260</td>\n",
              "      <td>0.073400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.173</td>\n",
              "      <td>13.86</td>\n",
              "      <td>59.20</td>\n",
              "      <td>260.9</td>\n",
              "      <td>0.07721</td>\n",
              "      <td>0.08751</td>\n",
              "      <td>0.05988</td>\n",
              "      <td>0.021800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22.270</td>\n",
              "      <td>19.67</td>\n",
              "      <td>152.80</td>\n",
              "      <td>1509.0</td>\n",
              "      <td>0.13260</td>\n",
              "      <td>0.27680</td>\n",
              "      <td>0.42640</td>\n",
              "      <td>0.182300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  concavity_mean  concave points_mean\n",
              "0       13.000         21.82  ...         0.18590             0.093530\n",
              "1        8.196         16.84  ...         0.01588             0.005917\n",
              "2       13.170         18.66  ...         0.12260             0.073400\n",
              "3        9.173         13.86  ...         0.05988             0.021800\n",
              "4       22.270         19.67  ...         0.42640             0.182300\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqmiCC_JWSHa",
        "outputId": "36c52f7f-ebc3-4cba-fa98-8aaeca627e06"
      },
      "source": [
        "test_pred = model1.predict(X_test1)\r\n",
        "print(test_pred)\r\n",
        "\r\n",
        "test_pred_categorical = [1 if pred > 0.5 else 0 for pred in test_pred]\r\n",
        "print(test_pred_categorical)\r\n",
        "\r\n",
        "test_pred_encoded = le.inverse_transform(test_pred_categorical)\r\n",
        "print(test_pred_encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.02236259]\n",
            " [0.00791666]\n",
            " [0.08078754]\n",
            " [0.00563475]\n",
            " [1.        ]\n",
            " [0.00439397]]\n",
            "[0, 0, 0, 0, 1, 0]\n",
            "['B' 'B' 'B' 'B' 'M' 'B']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVmeZC_0WaSi"
      },
      "source": [
        "## M2\r\n",
        "\r\n",
        "Let's build a more complex model with 30 features and more neurons. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "AVqr2n_XXA5-",
        "outputId": "eb437a32-8da8-4d83-bb50-04186d0ab8d8"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0        17.99         10.38  ...          0.4601                  0.11890\n",
              "1        20.57         17.77  ...          0.2750                  0.08902\n",
              "2        19.69         21.25  ...          0.3613                  0.08758\n",
              "3        11.42         20.38  ...          0.6638                  0.17300\n",
              "4        20.29         14.34  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D7T971GW30P"
      },
      "source": [
        "### Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAjQ_pImW6dX",
        "outputId": "d03c9654-073d-4d71-d36d-04174e8e2a21"
      },
      "source": [
        "# split data to train and validation sets\r\n",
        "X_train2, X_val2, y_train2, y_val2 = train_test_split(X, y, test_size=0.3, random_state=100)\r\n",
        "print(f'training data set size: {len(X_train2)}')\r\n",
        "print(f'validation data set size: {len(X_val2)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data set size: 398\n",
            "validation data set size: 171\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVyoUtRgXIId"
      },
      "source": [
        "### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-N_SGGRXrTO",
        "outputId": "b85e848d-176e-4afa-f23d-b7c28396ce69"
      },
      "source": [
        "# define the keras model\r\n",
        "model2 = Sequential()\r\n",
        "model2.add(Dense(64, input_dim=30, activation='relu'))\r\n",
        "model2.add(Dense(32, activation='relu'))\r\n",
        "model2.add(Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 64)                1984      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 4,097\n",
            "Trainable params: 4,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtdUabBbaQTd"
      },
      "source": [
        "# compile the keras model\r\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSchDfo0aYVz",
        "outputId": "7b67084e-feca-4a9f-eccf-391e82e8241f"
      },
      "source": [
        "# train model\r\n",
        "model2.fit(X_train2, y_train2, batch_size=50, epochs=60, validation_data=(X_val2, y_val2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "8/8 [==============================] - 1s 37ms/step - loss: 25.2042 - accuracy: 0.3803 - val_loss: 13.1142 - val_accuracy: 0.5965\n",
            "Epoch 2/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.3375 - accuracy: 0.5262 - val_loss: 2.5134 - val_accuracy: 0.3801\n",
            "Epoch 3/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.3495 - accuracy: 0.6040 - val_loss: 2.5220 - val_accuracy: 0.4561\n",
            "Epoch 4/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.6477 - accuracy: 0.5894 - val_loss: 0.3488 - val_accuracy: 0.8655\n",
            "Epoch 5/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4963 - accuracy: 0.8260 - val_loss: 0.4004 - val_accuracy: 0.8713\n",
            "Epoch 6/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3236 - accuracy: 0.9106 - val_loss: 0.2321 - val_accuracy: 0.9123\n",
            "Epoch 7/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3164 - accuracy: 0.8870 - val_loss: 0.2111 - val_accuracy: 0.9298\n",
            "Epoch 8/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2255 - accuracy: 0.9176 - val_loss: 0.2181 - val_accuracy: 0.9298\n",
            "Epoch 9/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2706 - accuracy: 0.9220 - val_loss: 0.2137 - val_accuracy: 0.9357\n",
            "Epoch 10/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2077 - accuracy: 0.9305 - val_loss: 0.2111 - val_accuracy: 0.9298\n",
            "Epoch 11/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2196 - accuracy: 0.9083 - val_loss: 0.2979 - val_accuracy: 0.9181\n",
            "Epoch 12/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3286 - accuracy: 0.9086 - val_loss: 0.1948 - val_accuracy: 0.9357\n",
            "Epoch 13/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2396 - accuracy: 0.9350 - val_loss: 0.2968 - val_accuracy: 0.8830\n",
            "Epoch 14/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2753 - accuracy: 0.8973 - val_loss: 0.1968 - val_accuracy: 0.9240\n",
            "Epoch 15/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3002 - accuracy: 0.9061 - val_loss: 0.3980 - val_accuracy: 0.8947\n",
            "Epoch 16/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3700 - accuracy: 0.9035 - val_loss: 0.1799 - val_accuracy: 0.9298\n",
            "Epoch 17/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1942 - accuracy: 0.9371 - val_loss: 0.2111 - val_accuracy: 0.9240\n",
            "Epoch 18/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3147 - accuracy: 0.8718 - val_loss: 0.1784 - val_accuracy: 0.9298\n",
            "Epoch 19/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2222 - accuracy: 0.9311 - val_loss: 0.2891 - val_accuracy: 0.9123\n",
            "Epoch 20/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2671 - accuracy: 0.9168 - val_loss: 0.1749 - val_accuracy: 0.9240\n",
            "Epoch 21/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2717 - accuracy: 0.9137 - val_loss: 0.3602 - val_accuracy: 0.8772\n",
            "Epoch 22/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3230 - accuracy: 0.9181 - val_loss: 0.2049 - val_accuracy: 0.9357\n",
            "Epoch 23/60\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3899 - accuracy: 0.8752 - val_loss: 0.5453 - val_accuracy: 0.8655\n",
            "Epoch 24/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3090 - accuracy: 0.8918 - val_loss: 0.4643 - val_accuracy: 0.8889\n",
            "Epoch 25/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4478 - accuracy: 0.8894 - val_loss: 0.2907 - val_accuracy: 0.9123\n",
            "Epoch 26/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3003 - accuracy: 0.9055 - val_loss: 0.2105 - val_accuracy: 0.9298\n",
            "Epoch 27/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1963 - accuracy: 0.9289 - val_loss: 0.2814 - val_accuracy: 0.9240\n",
            "Epoch 28/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2495 - accuracy: 0.9036 - val_loss: 0.1759 - val_accuracy: 0.9298\n",
            "Epoch 29/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1772 - accuracy: 0.9136 - val_loss: 0.1976 - val_accuracy: 0.9240\n",
            "Epoch 30/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2320 - accuracy: 0.9146 - val_loss: 0.3108 - val_accuracy: 0.9181\n",
            "Epoch 31/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2296 - accuracy: 0.9312 - val_loss: 0.1715 - val_accuracy: 0.9298\n",
            "Epoch 32/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1595 - accuracy: 0.9437 - val_loss: 0.1960 - val_accuracy: 0.9474\n",
            "Epoch 33/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1548 - accuracy: 0.9445 - val_loss: 0.1654 - val_accuracy: 0.9298\n",
            "Epoch 34/60\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.2005 - accuracy: 0.9249 - val_loss: 0.1890 - val_accuracy: 0.9240\n",
            "Epoch 35/60\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1934 - accuracy: 0.9241 - val_loss: 0.3441 - val_accuracy: 0.9064\n",
            "Epoch 36/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2216 - accuracy: 0.9172 - val_loss: 0.1998 - val_accuracy: 0.9240\n",
            "Epoch 37/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2293 - accuracy: 0.9140 - val_loss: 0.2449 - val_accuracy: 0.9181\n",
            "Epoch 38/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2309 - accuracy: 0.9264 - val_loss: 0.2273 - val_accuracy: 0.9181\n",
            "Epoch 39/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3110 - accuracy: 0.9073 - val_loss: 0.2112 - val_accuracy: 0.9240\n",
            "Epoch 40/60\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2646 - accuracy: 0.9081 - val_loss: 0.2140 - val_accuracy: 0.9240\n",
            "Epoch 41/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1378 - accuracy: 0.9543 - val_loss: 0.1833 - val_accuracy: 0.9298\n",
            "Epoch 42/60\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2656 - accuracy: 0.9274 - val_loss: 0.1939 - val_accuracy: 0.9298\n",
            "Epoch 43/60\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1917 - accuracy: 0.9269 - val_loss: 0.3078 - val_accuracy: 0.8947\n",
            "Epoch 44/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2156 - accuracy: 0.9124 - val_loss: 0.1737 - val_accuracy: 0.9298\n",
            "Epoch 45/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1991 - accuracy: 0.9244 - val_loss: 0.1458 - val_accuracy: 0.9298\n",
            "Epoch 46/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1416 - accuracy: 0.9420 - val_loss: 0.2000 - val_accuracy: 0.9240\n",
            "Epoch 47/60\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2357 - accuracy: 0.9124 - val_loss: 0.1412 - val_accuracy: 0.9357\n",
            "Epoch 48/60\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1774 - accuracy: 0.9341 - val_loss: 0.2016 - val_accuracy: 0.9240\n",
            "Epoch 49/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1710 - accuracy: 0.9366 - val_loss: 0.1415 - val_accuracy: 0.9357\n",
            "Epoch 50/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1594 - accuracy: 0.9350 - val_loss: 0.1385 - val_accuracy: 0.9357\n",
            "Epoch 51/60\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1890 - accuracy: 0.9297 - val_loss: 0.1402 - val_accuracy: 0.9357\n",
            "Epoch 52/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2057 - accuracy: 0.9328 - val_loss: 0.1443 - val_accuracy: 0.9357\n",
            "Epoch 53/60\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2134 - accuracy: 0.9363 - val_loss: 0.1559 - val_accuracy: 0.9240\n",
            "Epoch 54/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2214 - accuracy: 0.9186 - val_loss: 0.1657 - val_accuracy: 0.9298\n",
            "Epoch 55/60\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1791 - accuracy: 0.9417 - val_loss: 0.1673 - val_accuracy: 0.9240\n",
            "Epoch 56/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1253 - accuracy: 0.9582 - val_loss: 0.1372 - val_accuracy: 0.9357\n",
            "Epoch 57/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1583 - accuracy: 0.9509 - val_loss: 0.1360 - val_accuracy: 0.9357\n",
            "Epoch 58/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1561 - accuracy: 0.9403 - val_loss: 0.2258 - val_accuracy: 0.9181\n",
            "Epoch 59/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2270 - accuracy: 0.9135 - val_loss: 0.3614 - val_accuracy: 0.8655\n",
            "Epoch 60/60\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3054 - accuracy: 0.8881 - val_loss: 0.1386 - val_accuracy: 0.9357\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f811a10b518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGKq3EwPZJC2"
      },
      "source": [
        "### Test Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eRBbWtaZVsn",
        "outputId": "7559c7c5-142b-4ebd-fd08-dc78e60f73e2"
      },
      "source": [
        "df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Applied-AI/DL/data/cancer_data_test.csv')\r\n",
        "\r\n",
        "# summarise the details\r\n",
        "print(f'Number of entries: {len(df_test)}')\r\n",
        "\r\n",
        "X_test = df_test.drop(['id'], axis=1)\r\n",
        "print(X_test.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of entries: 6\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6 entries, 0 to 5\n",
            "Data columns (total 30 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   radius_mean              6 non-null      float64\n",
            " 1   texture_mean             6 non-null      float64\n",
            " 2   perimeter_mean           6 non-null      float64\n",
            " 3   area_mean                6 non-null      float64\n",
            " 4   smoothness_mean          6 non-null      float64\n",
            " 5   compactness_mean         6 non-null      float64\n",
            " 6   concavity_mean           6 non-null      float64\n",
            " 7   concave points_mean      6 non-null      float64\n",
            " 8   symmetry_mean            6 non-null      float64\n",
            " 9   fractal_dimension_mean   6 non-null      float64\n",
            " 10  radius_se                6 non-null      float64\n",
            " 11  texture_se               6 non-null      float64\n",
            " 12  perimeter_se             6 non-null      float64\n",
            " 13  area_se                  6 non-null      float64\n",
            " 14  smoothness_se            6 non-null      float64\n",
            " 15  compactness_se           6 non-null      float64\n",
            " 16  concavity_se             6 non-null      float64\n",
            " 17  concave points_se        6 non-null      float64\n",
            " 18  symmetry_se              6 non-null      float64\n",
            " 19  fractal_dimension_se     6 non-null      float64\n",
            " 20  radius_worst             6 non-null      float64\n",
            " 21  texture_worst            6 non-null      float64\n",
            " 22  perimeter_worst          6 non-null      float64\n",
            " 23  area_worst               6 non-null      float64\n",
            " 24  smoothness_worst         6 non-null      float64\n",
            " 25  compactness_worst        6 non-null      float64\n",
            " 26  concavity_worst          6 non-null      float64\n",
            " 27  concave points_worst     6 non-null      float64\n",
            " 28  symmetry_worst           6 non-null      float64\n",
            " 29  fractal_dimension_worst  6 non-null      float64\n",
            "dtypes: float64(30)\n",
            "memory usage: 1.5 KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz0mBIJ3Zd7Y",
        "outputId": "6b760020-b7cb-4d9c-ac5a-dcdf3bc59656"
      },
      "source": [
        "test_pred = model2.predict(X_test)\r\n",
        "print(test_pred)\r\n",
        "\r\n",
        "test_pred_categorical = [1 if pred > 0.5 else 0 for pred in test_pred]\r\n",
        "print(test_pred_categorical)\r\n",
        "\r\n",
        "test_pred_encoded = le.inverse_transform(test_pred_categorical)\r\n",
        "print(test_pred_encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.8215139 ]\n",
            " [0.00703016]\n",
            " [0.88419247]\n",
            " [0.00459763]\n",
            " [1.        ]\n",
            " [0.30599135]]\n",
            "[1, 0, 1, 0, 1, 0]\n",
            "['M' 'B' 'M' 'B' 'M' 'B']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoX56hNTaYHm"
      },
      "source": [
        "## Randomness in neural networks\r\n",
        "\r\n",
        "Intial weights of a neural network are assigned randomly. Therefore, for same data set with same structure and parameter setting results can be slightly varied at different runs. <br>\r\n",
        "Example: If you train model M2 twice, you will not obtain same accuracy for both runs. "
      ]
    }
  ]
}